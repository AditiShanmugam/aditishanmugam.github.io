<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Google tag (gtag.js) -->
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-H9J99M9X7B');
  </script>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/css/bootstrap.min.css" />
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.0/dist/js/bootstrap.bundle.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" />
  <link rel="stylesheet" href="assets/css/style.css" />

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />

  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Barlow:wght@100&display=swap" rel="stylesheet" />
  <script src="https://kit.fontawesome.com/e5211f5b2b.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" type="text/css" href="./index.css" />
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-H9J99M9X7B"></script>


  <title>Aditi Shanmugam | Computer Vision Engineeer | IISc | Fellowship.ai | BMSIT&M | Inferigence Quotient</title>
</head>

<body>
  <!-- Navigation bar Display -->
  <navigation-bar>
    <div class="nav-bar">
      <ul>
        <!-- Add links -->
        <!-- <a style="padding-right: 20px" href="" id="nav-anchors"> Home </a> -->
        <a style="padding-right: 10px" href="#WORKEX" id="nav-anchors"> Work Experience </a>
        <a style="padding-right: 10px" href="#PROJECTS" id="nav-anchors"> Projects </a>
        <a style="padding-right: 10px" href="./AditiShanmugam_Resume.pdf" id="nav-anchors"> Resume </a>
      </ul>
    </div>
    <div class="title">
      <ul>
        <!-- Add links -->
        <a href="" id="nav-anchors"> ADITI SHANMUGAM </a>
      </ul>
    </div>
  </navigation-bar>

  <!-- About Aditi -->
  <div class="container text-center mt-5">
    <div class="jumbortron text-center" id="jt1">
      <img src="./img/avatar2.jpeg" alt="Aditi" class="avatar">
      <p>
        <br>
        [<i>Img : Aditi Shanmugam.</i>]
      </p>
      </p>
      <!-- <p>
        I graduated with a Bachelor's degree in Electronics and Telecommunications Engineering from <a
          href="https://vtu.ac.in/en/">Visveswaraya Technological University</a> in July '22. During my undergraduate
        journey, I had the privilege of gaining valuable professional experiences that significantly influenced my
        career path in the field of Robotics.
        I began my journey as a Data Science Fellow at <a href="https://www.fellowship.ai">Fellowship.ai</a>, where I
        immersed myself in the intricacies of Machine Learning and AI, acquiring valuable skills and insights. I then
        had the opportunity to work as a research intern at the <a href="http://visual-computing.in/home/">Visual
          Computing Lab</a> within the <a href="https://cds.iisc.ac.in">Department of Computational Data Sciences</a> at
        the prestigious <a href="https://iisc.ac.in">Indian Institute of Science, Bangalore</a>. This role not only
        broadened my horizons but also deepened my understanding of advanced research in the field of Deep Learning.
        A brief yet impactful tenure as a Computer Vision intern at <a
          href="https://www.inferq.com/default.aspx">Inferigence Quotient</a>, a trailblazing defense tech startup where
        my contributions were well-received, led to a full-time position as a Computer Vision Engineer, a role I
        currently hold.
        These diverse experiences have equipped me with a solid foundation in Electronics, Telecommunications, and Data
        Science that renders me exceptionally proficient as a robotics engineer. </p> -->
      <p>
        Hi! Iâ€™m Aditi, a Machine Learning Engineer with a deep passion for robotics and a vision to innovate in the
        world of technology. My journey began with a Bachelor's degree in Electronics and Telecommunications Engineering
        from <a href="https://vtu.ac.in/en/">Visveswaraya Technological University</a> in July '22, laying the
        foundation for my career in the fast-evolving field of AI and Machine Learning.

        My professional path has been shaped by diverse experiences that have broadened my expertise. At <a
          href="https://www.fellowship.ai">Fellowship.ai</a>, I delved into the intricacies of Machine Learning, gaining
        critical skills that propelled my journey forward. As a research intern at the <a
          href="http://visual-computing.in/home/">Visual Computing Lab</a> within the <a
          href="https://cds.iisc.ac.in">Department of Computational Data Sciences</a> at the prestigious <a
          href="https://iisc.ac.in">Indian Institute of Science, Bangalore</a>, I was immersed in cutting-edge research
        in Deep Learning, enhancing my technical acumen.

        My tenure at <a href="https://www.inferq.com/default.aspx">Inferigence Quotient</a>, a pioneering defense tech
        startup, began as a Computer Vision intern, where I contributed to projects with significant real-world impact.
        This role quickly evolved into a full-time position as a Computer Vision Engineer, where I currently work on
        advanced systems that push the boundaries of AI in defense technology.

        These experiences, combined with my continuous pursuit of knowledge, have equipped me with a robust foundation
        in electronics, telecommunications, and data science. As I continue to grow in this dynamic field, I am driven
        by a goal to pioneer advancements in robotics and AI, with aspirations to further my work in Japan.
      </p>

    </div>
    <br></br>
    <!-- End of About Aditi -->

    <!-- Work Exp -->
    <div class="container text-center mt-5" id="WORKEX">
      <h3>Work Experience</h3>
    </div>
    <br></br>

    <div class="jumbotron" id="jt_workex_2">
      <div class="container" id="con_workexp_align">
        <div class="row">
          <div class="col" id="col_custom_workex2">
            <img src="./img/iq.png" alt="pix" class="workex_img">
            <br></br>

            <p class="workex_title"><a href="https://www.inferq.com/default.aspx">Inferigence Quotient</a></p>
            <p class="workex_lvl_2">Machine Learning Enginner (Computer Vision), Ex-Intern</p>
            <p class="workex_lvl_3">April '22 - Present</p>
            <p class="workex_lvl_3">As a Machine Learning Engineer at Inferigence Quotient, I led the development and
              deployment of cutting-edge computer vision solutions, focusing on real-time object detection and
              recognition systems. My work involved spearheading a cross-functional team in the creation of an Automatic
              Number Plate Recognition (ANPR) system, which significantly improved detection accuracy and reduced manual
              tracking errors across multiple deployment sites. I also engineered a high-performance object recognition
              pipeline for UAVs, which enhanced operational efficiency in surveillance missions by 30% and reduced
              processing time by 50%. Additionally, I developed a real-time georeferencing system for UAV-captured
              images, achieving 95% accuracy in aligning images with satellite imagery, thereby improving geolocation
              accuracy by 40%. My contributions not only advanced the technical capabilities of our systems but also
              directly impacted client operations by providing reliable, scalable solutions. </p>
          </div>
          <div class="col" id="col_custom_workex2">
            <p class="workex_lvl_3">Primary Tasks and Responsibilities:</p>

            <!-- <ol> -->
            1. Automatic Number Plate Recognition - ANPR
            <ul class="workex_lvl_3">
              <li>Directed a cross-functional team of 8 data engineers and ML engineers in the deployment of a scalable
                number plate tracking solution, incorporating custom OCR correction logic specifically tailored for
                Indian number plates.</li>
              <li>Orchestrated the development and integration of advanced detection algorithms that elevated detection
                accuracy to over 95%, significantly enhancing data integrity; this initiative led to a reduction in
                error rates to under 2% and greatly improved service reliability for law enforcement and civilian
                applications.</li>
              <li>Successfully deployed the software solutions at 10 toll plazas, resulting in a 40% reduction in manual
                tracking errors and empowering law enforcement agencies to respond to traffic violations in real-time,
                significantly improving operational efficiency.</li>
            </ul>


            2. System for Tracking And Recognition of Targets - iSTART
            <ul class="workex_lvl_3">
              <li>Engineered a robust object recognition and tracking pipeline for deployment within Unmanned Aerial
                Vehicles (UAVs), implementing state-of-the-art tracking algorithms such as DeepSort alongside
                custom-trained YOLOv7 models, optimized for real-time performance.</li>
              <li>Utilized frameworks and libraries including OpenCV, TensorRT, and onnxruntime in C++ to design and
                develop the system, ensuring it was fully optimized for deployment on Jetson devices, thus achieving
                high efficiency and low latency in aerial surveillance applications.</li>
              <li>Led the development of an in-house image annotation tool and oversaw the curation of custom datasets
                tailored for deep learning projects, managing and mentoring a team of 3 members to ensure the successful
                delivery of high-quality data for model training.</li>
            </ul>


            3. Real-time Georeferencing of Aerial Infrared (IR) Video - GeoAIR
            <ul class="workex_lvl_3">
              <li>Leveraged Python and OpenCV to develop a precise frame registration pipeline, aligning UAV-captured
                infrared images with satellite imagery to achieve accurate geo-location for real-time aerial
                surveillance applications.</li>
              <li>Incorporated advanced template matching algorithms combined with sparse and dense optic flow
                techniques, achieving close to 90% frame registration accuracy and delivering performance on HD videos
                with latency under 500ms and throughput of 25fps on a moderate capacity GPU, meeting stringent real-time
                operational requirements.</li>
            </ul>

            <!-- </ol> -->

          </div>
        </div>

        <div class="row">
          <div class="col" id="col_custom_workex2">
            <img src="./img/vcl.jpg" alt="pix" class="workex_img">
            <br></br>

            <p class="workex_title"><a href="https://visual-computing.in/team/">Visual Computing Lab, Indian Institute
                of Science (IISc)</a></p>
            <p class="workex_lvl_2">Research Intern (Deep Learning) </p>
            <p class="workex_lvl_3">May '21 - April '22</p>
            <p class="workex_lvl_3">Former Research Intern under Professor Anirban Chakraborty at the <a
                href="http://visual-computing.in/home/">Visual Computing Laboratory</a>, operated by the Department of
              <a href="https://cds.iisc.ac.in">Computational Data Sciences</a>, at the <a
                href="https://iisc.ac.in">Indian Institute of Sciences (IISc)</a>.
              As a Research Intern at the Visual Computing Lab, IISc, I contributed to the development of advanced deep
              learning models for domain adaptation and image inpainting. I collaborated on integrating the Divide-Mix
              algorithm into the Source-Free Multi-Label Domain Adaptation (SF-MLDA) framework, which led to a 7%
              increase in model accuracy by mitigating data noise. Additionally, I worked on developing neural networks
              that utilized Generative Adversarial Networks (GANs) and Autoencoders, resulting in a 30% improvement in
              anomaly detection efficiency. My research focused on advancing the state-of-the-art in these areas, with
              outcomes that were not only academically significant but also had practical implications for improving the
              reliability and robustness of machine learning models.
            </p>
          </div>
          <div class="col" id="col_custom_workex2">
            <p class="workex_lvl_3">Primary Tasks and Responsibilities:</p>

            1. Source Free Multi-Label Domain Adaptation - SF-MLDA
            <ul class="workex_lvl_3">
              <li>Played a pivotal role in the development of an advanced framework for performing Source-Free
                Multi-Label Domain Adaptation (SF-MLDA), leveraging cutting-edge techniques to address domain shift
                challenges in machine learning.</li>
              <li>Spearheaded the integration of a co-teaching algorithm called Divide-Mix to effectively mitigate noise
                in training data within the SF-MLDA framework, resulting in a measurable 7.0% improvement in model
                accuracy and robustness.</li>
            </ul>


            2. Superpixel Masking and Image Inpainting - SMAI
            <ul class="workex_lvl_3">
              <li>Led the development and optimization of two neural networks inspired by Generative Adversarial
                Networks (GANs) and Autoencoders for advanced anomaly detection, localization, and correction,
                significantly improving the systemâ€™s effectiveness.</li>
              <li>Conducted in-depth experiments with structural and reconstruction loss functions to establish a strong
                correlation between image inpainting quality and reconstruction accuracy, contributing to the refinement
                of the overall pipeline.</li>
              <li>Enhanced the anomaly detection pipeline by incorporating multi-exposure fusion techniques for
                synthetic image regeneration, achieving a remarkable 80.0% overall accuracy rate, setting a new standard
                for image inpainting applications.</li>
            </ul>

          </div>
        </div>

        <div class="container" id="con_workexp_align">
          <div class="row">
            <div class="col" id="col_custom_workex2">
              <img src="./img/fellowship.jpeg" alt="pix" class="workex_img">
              <br></br>

              <p class="workex_title"><a href="https://www.fellowship.ai">Fellowship.ai</a></p>
              <p class="workex_lvl_2">Data Science Fellow</p>
              <p class="workex_lvl_3">January '21 - April '21</p>
              <p class="workex_lvl_3">
                I was part of the four month Machine Learning Fellowship program offered by <a
                  href="https://www.fellowship.ai">Fellowship.ai</a>, a subsidary of <a
                  href="https://www.launchpad.ai/">launchpad.ai.</a>
                During my tenure as a Data Science Fellow at Fellowship.ai, I developed a zero-shot object detection web
                application tailored for culinary environments. By refining the Language-Image Pre-training (CLIP)
                model, I achieved a Top-1 accuracy of 97.22% and a perfect Top-3 accuracy of 100%, using a dataset of
                just 16 images across over 100 classes. This web application became integral to daily operations,
                enabling real-time ingredient recognition and significantly streamlining kitchen processes. My work
                involved not only model refinement and deployment but also ensuring that the application could perform
                effectively in a production environment, delivering practical, real-world benefits to the users. </p>
            </div>
            <div class="col" id="col_custom_workex2">
              <p class="workex_lvl_3">Primary Tasks and Responsibilities:</p>
              1. Novel Food Type Detection
              <ul class="workex_lvl_3">
                <li>Developed an end-to-end functional web application using Streamlit to perform zero-shot object
                  detection for food items in an in-oven setting, enabling real-time identification and monitoring
                  within culinary environments.</li>
                <li>Established baseline results by leveraging ResNet50 and ResNet101 networks through transfer learning
                  and training from scratch on custom datasets, effectively setting the foundation for advanced model
                  improvements.</li>
                <li>Utilized OpenAI's state-of-the-art Contrastive Language-Image Pre-training model, CLIP, to achieve
                  remarkable performance, attaining a Top-1 accuracy of 97.22% and a perfect Top-3 accuracy of 100.0% on
                  a custom dataset containing approximately 16 images per class.</li>
                <li>Developed and implemented web scrapers using Scrapy and Selenium to generate custom datasets by
                  extracting images from food blogs and Instagram. Enhanced the dataset size and diversity through data
                  augmentation techniques, significantly improving model robustness.</li>
              </ul>

            </div>
          </div>
        </div>

        <!-- WorkExp End-->

        <!-- Projects Start -->
        <div class="container text-center mt-5" id="PROJECTS">
          <h3>Projects</h3>
        </div>

        <br></br>

        <div class="container" id="conmain_proj">
          <div class="jumbotron" id="jt_proj1">
            <div class="container" id="con1">

              <div class="row" id="proj_row">
                <div class="col" id="proj_col1">
                  <img src="./img/FYP.png" alt="pix" class="Projpix">
                </div>
                <div class="col" id="col">
                  <p class="level2">Multi-Modal Machine Learning for Object Detection.</p>
                  <p class="level3">This work was conducted as my Undergraduate degree thesis under the guidance of
                    <a href="https://bmsit.irins.org/profile/115991">Prof.Pratibha N</a>, assistant professor at the
                    Department of Electronics and Telecommunications Engineering at
                    <a href="https://bmsit.ac.in">BMS Institute of Technology and Management</a>.
                    The main aim of this project is to demonstrate the significant improvements in Computer Vision upon
                    integrating contextual understanding used in Natural Language Processing tasks.
                    The Contrastive Language Image Pretraining task uses multimodal data as Image-Text pairs, in
                    Zero-shot or Few-shot settings. This work has been accepted to the
                    <a href="https://scril.sau.int/ijcaci22/">6th International Joint Conference on Advances in
                      Computational Intelligence (IJCACI 2022)</a>.
                  </p>
                  <p class="level4">
                    <a href="https://link.springer.com/chapter/10.1007/978-981-99-1435-7_2">Paper</a> |
                    <a href="https://github.com/AditiShanmugam/Thesis-CLIP-For-Object-Detection">Code</a>
                  </p>
                </div>
              </div>
              <br></br>

              <div class="row" id="proj_row">
                <div class="col" id="proj_col1">
                  <img src="./img/SF_MLDA.png" alt="pix" class="Projpix">
                </div>
                <div class="col" id="col">
                  <p class="level2">Source Free - Multi Label Domain Adaptation</p>
                  <p class="level3">This work introduces a novel concept of Source-Free Multi-Label Domain Adaptation
                    (SF-MLDA) using graph convolution networks (GCN) and a Co-teaching based method to tackle the
                    problem of noisy labels. In summary, this research work aims to improve the task of adapting a deep
                    learning
                    model to a new domain (distribution of data) where instances have multiple labels, in the absence of
                    a labeled source domain to aid in the adaptation process. My work was carried out in coalition with
                    <a href="https://www.linkedin.com/in/vikash0837/">Vikash Kumar</a>, a Masters student, and his
                    advisor
                    <a href="https://cds.iisc.ac.in/people/faculty/name/anirban-chakraborty/">Prof.Anirban
                      Chakraborty</a>
                    at the <a href="https://iisc.ac.in">Indian Institute of Science</a>, during my Internship at the
                    <a href="http://visual-computing.in/home/">Visual Computing Lab</a>.
                  </p>
                </div>
              </div>
              <br></br>

              <div class="row" id="proj_row">
                <div class="col" id="proj_col1">
                  <img src="./img/SMAI.jpg" alt="pix" class="Projpix">
                </div>
                <div class="col" id="col">
                  <p class="level2">Superpixel Masking and Image Inpainting with Multi Exposure Fusion</p>
                  <p class="level3">The aim of this research was to improve Anomaly Detection and Correction using
                    Superpixel Masking and Inpainting. To enhance existing methods, the network was designed by
                    employing a mask-based curriculum learning approach and incorporating multi-image exposure.
                    Two variants of the network were developed, taking inspiration from Generative Adversarial Networks
                    (GAN) and Autoencoder-based architectures. This work aims to improve applications such as image
                    restoration,
                    where damaged or missing parts of an image need to be reconstructed while maintaining the overall
                    image quality.
                    I collaborated with <a href="https://www.linkedin.com/in/adityakumarpal17059/">Aditya Kumar Pal</a>,
                    a former Masters student, and his advisor
                    <a href="https://cds.iisc.ac.in/people/faculty/name/anirban-chakraborty/">Prof.Anirban
                      Chakraborty</a>
                    at the <a href="https://iisc.ac.in">Indian Institute of Science</a>, during my Internship at the
                    <a href="http://visual-computing.in/home/">Visual Computing Lab</a>.
                  </p>
                </div>
              </div>
              <br></br>

              <div class="row" id="proj_row">
                <div class="col" id="proj_col1">
                  <img src="./img/Project1.jpeg" alt="pix" class="Projpix">
                </div>
                <div class="col" id="col1">
                  <p class="level2">Dry Waste Classification Using Machine Learning and IoT</p>
                  <p class="level3">The primary objective of this project was to develop a simple yet efficient machine
                    learning-powered device to perform waste classification on organic and inorganic waste.
                    Additionally, a paper about the work was submitted to the
                    <a href="https://www.amity.edu/iciem2021/">2nd International Conference On Intelligent Engineering
                      And Management, 2021</a>.
                    The project also acquired small-scale funding of INR 20,000 to develop a fully functional prototype
                    to scale. This project was carried out under
                    <a href="https://bmsit.irins.org/profile/115992">Dr. Mallikarjuna Gowda C.P</a>, Associate professor
                    at the Department of
                    Electronics and Telecommunications Engineering at
                    <a href="https://bmsit.ac.in">BMS Institute of Technology and Management</a>.
                  </p>
                  <p class="level4">
                    <a
                      href="https://ieeexplore.ieee.org/abstract/document/9445289?casa_token=v6RZy51ykJsAAAAA:RMqo0BAzm0CzXulCPS9RvS98SNTUGgcOpuiRSacfhDYwF6okz6rbi5tBiF2XluEqtGfS80A6Lg">Paper</a>
                    |
                    <a href="https://github.com/AditiShanmugam/Dry-Waste-Classification">Code</a>
                  </p>
                </div>
              </div>
              <br></br>
            </div>
            <br></br>
          </div>
        </div>

        <!-- Projects End -->

        <!-- FOOTER -->

        <div class="footer-basic">
          <footer>
            <div class="social">
              <a href="https://github.com/AditiShanmugam" style="font-size: 25px" class="fa-brands fa-github"
                id="footer-nav-anchors">
              </a>
              <a href="https://www.linkedin.com/in/aditi-shanmugam" style="font-size: 25px"
                class="fa-brands fa-linkedin" id="footer-nav-anchors">
              </a>
              <a href="https://twitter.com/aditi_shanmugam" style="font-size: 25px" class="fa-brands fa-twitter"
                id="footer-nav-anchors">
              </a>
              <a href=mailto:aditishanmugam1@gmail.com style="font-size: 25px" class="fa-solid fa-envelope"
                id="footer-nav-anchors">
              </a>
            </div>

            <p class="copyright">Aditi Shanmugam. Â© 2023</p>
          </footer>
        </div>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
        <script
          src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.bundle.min.js"></script>
</body>

</html>